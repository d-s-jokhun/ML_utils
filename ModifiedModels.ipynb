{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nCh_adjuster (NumOfInputCh=1, NumOfOutputCh=3, ImgSize=224):\n",
    "    \n",
    "    In = keras.Input(shape=(ImgSize, ImgSize, NumOfInputCh))\n",
    "    Out = keras.layers.Conv2D(NumOfOutputCh, 1, padding=\"same\", activation=\"relu\", name=\"ThreeSinglePixFilters\")(In)\n",
    "    nCh_adjuster = keras.Model(inputs=In, outputs=Out, name=\"nCh_adjuster\")\n",
    "    \n",
    "    return nCh_adjuster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified VGG16\n",
    "\n",
    "def mod_VGG16 (NumOfClasses, NumOfInputCh=1, ImgSize=224, Weights=None, Include_Top=True):\n",
    "    \n",
    "    Preprocess = nCh_adjuster(\n",
    "        NumOfInputCh=NumOfInputCh, \n",
    "        NumOfOutputCh=3, \n",
    "        ImgSize=ImgSize\n",
    "    )\n",
    "    \n",
    "    VGG16=keras.applications.VGG16(\n",
    "        include_top=True,\n",
    "        weights=Weights,\n",
    "        input_tensor=Preprocess.outputs[0],\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=NumOfClasses\n",
    "    )\n",
    "\n",
    "    mod_VGG16 = keras.Model(inputs=Preprocess.inputs, outputs=VGG16.outputs, name=\"mod_VGG16\")\n",
    "\n",
    "    mod_VGG16.compile(\n",
    "        optimizer='adam', \n",
    "        loss='sparse_categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )   \n",
    "    \n",
    "    return mod_VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified VGG19\n",
    "\n",
    "def mod_VGG19 (NumOfClasses, NumOfInputCh=1, ImgSize=224, Weights=None, Include_Top=True):\n",
    "    \n",
    "    Preprocess = nCh_adjuster(\n",
    "        NumOfInputCh=NumOfInputCh, \n",
    "        NumOfOutputCh=3, \n",
    "        ImgSize=ImgSize\n",
    "    )\n",
    "    \n",
    "    VGG19=keras.applications.VGG19(\n",
    "        include_top=True,\n",
    "        weights=Weights,\n",
    "        input_tensor=Preprocess.outputs[0],\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=NumOfClasses\n",
    "    )\n",
    "\n",
    "    mod_VGG19 = keras.Model(inputs=Preprocess.inputs, outputs=VGG19.outputs, name=\"mod_VGG19\")\n",
    "\n",
    "    mod_VGG19.compile(\n",
    "        optimizer='adam', \n",
    "        loss='sparse_categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )   \n",
    "    \n",
    "    return mod_VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified ResNet50\n",
    "\n",
    "def mod_ResNet50 (NumOfClasses, NumOfInputCh=1, ImgSize=224, Weights=None, Include_Top=True):\n",
    "    \n",
    "    Preprocess = nCh_adjuster(\n",
    "        NumOfInputCh=NumOfInputCh, \n",
    "        NumOfOutputCh=3, \n",
    "        ImgSize=ImgSize\n",
    "    )\n",
    "    \n",
    "    ResNet50=keras.applications.ResNet50(\n",
    "        include_top=True,\n",
    "        weights=Weights,\n",
    "        input_tensor=Preprocess.outputs[0],\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=NumOfClasses\n",
    "    )\n",
    "\n",
    "    mod_ResNet50 = keras.Model(inputs=Preprocess.inputs, outputs=ResNet50.outputs, name=\"mod_ResNet50\")\n",
    "\n",
    "    mod_ResNet50.compile(\n",
    "        optimizer='adam', \n",
    "        loss='sparse_categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )   \n",
    "    \n",
    "    return mod_ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified ResNet50V2\n",
    "\n",
    "def mod_ResNet50V2 (NumOfClasses, NumOfInputCh=1, ImgSize=224, Weights=None, Include_Top=True):\n",
    "    \n",
    "    Preprocess = nCh_adjuster(\n",
    "        NumOfInputCh=NumOfInputCh, \n",
    "        NumOfOutputCh=3, \n",
    "        ImgSize=ImgSize\n",
    "    )\n",
    "    \n",
    "    ResNet50V2=keras.applications.ResNet50V2(\n",
    "        include_top=True,\n",
    "        weights=Weights,\n",
    "        input_tensor=Preprocess.outputs[0],\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=NumOfClasses\n",
    "    )\n",
    "\n",
    "    mod_ResNet50V2 = keras.Model(inputs=Preprocess.inputs, outputs=ResNet50V2.outputs, name=\"mod_ResNet50V2\")\n",
    "\n",
    "    mod_ResNet50V2.compile(\n",
    "        optimizer='adam', \n",
    "        loss='sparse_categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )   \n",
    "    \n",
    "    return mod_ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified InceptionV3\n",
    "\n",
    "def mod_InceptionV3 (NumOfClasses, NumOfInputCh=1, ImgSize=224, Weights=None, Include_Top=True):\n",
    "    \n",
    "    Preprocess = nCh_adjuster(\n",
    "        NumOfInputCh=NumOfInputCh, \n",
    "        NumOfOutputCh=3, \n",
    "        ImgSize=ImgSize\n",
    "    )\n",
    "    \n",
    "    InceptionV3=keras.applications.InceptionV3(\n",
    "        include_top=True,\n",
    "        weights=Weights,\n",
    "        input_tensor=Preprocess.outputs[0],\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=NumOfClasses\n",
    "    )\n",
    "\n",
    "    mod_InceptionV3 = keras.Model(inputs=Preprocess.inputs, outputs=InceptionV3.outputs, name=\"mod_InceptionV3\")\n",
    "\n",
    "    mod_InceptionV3.compile(\n",
    "        optimizer='adam', \n",
    "        loss='sparse_categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )   \n",
    "    \n",
    "    return mod_InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified Xception\n",
    "\n",
    "def mod_Xception (NumOfClasses, NumOfInputCh=1, ImgSize=224, Weights=None, Include_Top=True):\n",
    "    \n",
    "    Preprocess = nCh_adjuster(\n",
    "        NumOfInputCh=NumOfInputCh, \n",
    "        NumOfOutputCh=3, \n",
    "        ImgSize=ImgSize\n",
    "    )\n",
    "    \n",
    "    Xception=keras.applications.Xception(\n",
    "        include_top=True,\n",
    "        weights=Weights,\n",
    "        input_tensor=Preprocess.outputs[0],\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=NumOfClasses\n",
    "    )\n",
    "\n",
    "    mod_Xception = keras.Model(inputs=Preprocess.inputs, outputs=Xception.outputs, name=\"mod_Xception\")\n",
    "\n",
    "    mod_Xception.compile(\n",
    "        optimizer='adam', \n",
    "        loss='sparse_categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "\n",
    "    return mod_Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified InceptionResNetV2\n",
    "\n",
    "def mod_InceptionResNetV2 (NumOfClasses, NumOfInputCh=1, ImgSize=224, Weights=None, Include_Top=True):\n",
    "    \n",
    "    Preprocess = nCh_adjuster(\n",
    "        NumOfInputCh=NumOfInputCh, \n",
    "        NumOfOutputCh=3, \n",
    "        ImgSize=ImgSize\n",
    "    )\n",
    "    \n",
    "    InceptionResNetV2=keras.applications.InceptionResNetV2(\n",
    "        include_top=True,\n",
    "        weights=Weights,\n",
    "        input_tensor=Preprocess.outputs[0],\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=NumOfClasses\n",
    "    )\n",
    "\n",
    "    mod_InceptionResNetV2 = keras.Model(inputs=Preprocess.inputs, outputs=InceptionResNetV2.outputs, name=\"mod_InceptionResNetV2\")\n",
    "\n",
    "    mod_InceptionResNetV2.compile(\n",
    "        optimizer='adam', \n",
    "        loss='sparse_categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "   \n",
    "    \n",
    "    return mod_InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified NasNetLarge\n",
    "\n",
    "def mod_NASNetLarge (NumOfClasses, NumOfInputCh=1, ImgSize=224, Weights=None, Include_Top=True):\n",
    "    \n",
    "    Preprocess = nCh_adjuster(\n",
    "        NumOfInputCh=NumOfInputCh, \n",
    "        NumOfOutputCh=3, \n",
    "        ImgSize=ImgSize\n",
    "    )\n",
    "    \n",
    "    NASNetLarge=keras.applications.NASNetLarge(\n",
    "        include_top=True,\n",
    "        weights=Weights,\n",
    "        input_tensor=Preprocess.outputs[0],\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=NumOfClasses\n",
    "    )\n",
    "\n",
    "    mod_NASNetLarge = keras.Model(inputs=Preprocess.inputs, outputs=NASNetLarge.outputs, name=\"mod_NASNetLarge\")\n",
    "\n",
    "    mod_NASNetLarge.compile(\n",
    "        optimizer='adam', \n",
    "        loss='sparse_categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "   \n",
    "    \n",
    "    return mod_NASNetLarge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
